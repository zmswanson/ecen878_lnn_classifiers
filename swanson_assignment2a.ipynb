{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2A: Binary Classification with Logisitic Regression\n",
    "\n",
    "### Task/Problem Statement:\n",
    "The goal of this part of the assignment is to predict whether a person earns over 50K annually based\n",
    "on the UCI Adult Income dataset as described below. The predict shall be achieved via Logistic\n",
    "Regression implemented via an LNN model using TensorFlow Keras API.\n",
    "\n",
    "### Dataset: UCI Adult Income (\"Census Income\") Dataset\n",
    "The UCI Adult Income Dataset (also known as the “Census Income” dataset) adult.csv comprises 14\n",
    "attributes including categorical and numerical features. The target “income” class is a binary\n",
    "variable (<=50K, >50K). The prediction task is to determine whether a person makes over 50K a year.\n",
    "\n",
    "Data provided in adult.xlsx comprises 14 attributes including categorical and numerical features.\n",
    "The target “income” class is a binary variable (<=50K, >50K).\n",
    "\n",
    "##### Source: https://archive.ics.uci.edu/dataset/2/adult\n",
    "\n",
    "##### Input variables:\n",
    "- age\n",
    "- workclass\n",
    "- fnlwgt\n",
    "- education\n",
    "- education-num\n",
    "- marital-status\n",
    "- occupation\n",
    "- relatioship\n",
    "- race\n",
    "- sex\n",
    "- capital-gain\n",
    "- capital-loss\n",
    "- hours-per-week\n",
    "- native-country\n",
    "\n",
    "##### Output variable: \n",
    "- Income (<=50K, >50K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adult_preprocessing import AdultPreprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Display Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age          workclass  fnlwgt   education  education-num  \\\n",
      "0   NaN          State-gov   77516   Bachelors             13   \n",
      "1  50.0   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2  38.0            Private  215646     HS-grad              9   \n",
      "3  53.0            Private  234721        11th              7   \n",
      "4  28.0            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation     relatioship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n"
     ]
    }
   ],
   "source": [
    "df_raw = None\n",
    "\n",
    "# the following try-except block tries to handle alternate file types for the data\n",
    "try:\n",
    "    df_raw = pd.read_csv(\"adult.csv\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        df_raw = pd.read_excel(\"adult.xlsx\", sheet_name=\"in\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"adult.xlsx or adult.csv not found\")\n",
    "        exit(1)\n",
    "\n",
    "print(df_raw.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             32560 non-null  float64\n",
      " 1   workclass       32561 non-null  object \n",
      " 2   fnlwgt          32561 non-null  int64  \n",
      " 3   education       32561 non-null  object \n",
      " 4   education-num   32561 non-null  int64  \n",
      " 5   marital-status  32561 non-null  object \n",
      " 6   occupation      32561 non-null  object \n",
      " 7   relatioship     32561 non-null  object \n",
      " 8   race            32561 non-null  object \n",
      " 9   sex             32561 non-null  object \n",
      " 10  capital-gain    32561 non-null  int64  \n",
      " 11  capital-loss    32561 non-null  int64  \n",
      " 12  hours-per-week  32561 non-null  int64  \n",
      " 13  native-country  32561 non-null  object \n",
      " 14  income          32561 non-null  object \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the dataset information.\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values in the dataset (display using the print method) and handle them using\n",
    "appropriate techniques. Finally, display whether missing values exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column `age` has 1 missing values imputed with median\n",
      "Column `workclass` has 1836 missing values imputed with mode\n",
      "Column `occupation` has 1843 missing values imputed with mode\n",
      "Column `native-country` has 583 missing values imputed with mode\n"
     ]
    }
   ],
   "source": [
    "# Assuming that we may use the adult income dataset again, I just put the general preprocessing code\n",
    "# from assignment 1 into a class in a separate file to keep this notebook clean.\n",
    "ap = AdultPreprocessing(df_raw)\n",
    "ap.fix_question_marks()\n",
    "ap.impute_missing_values(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical variables into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.one_hot_encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame “df” that includes both numeric and encoded categorical columns without\n",
    "redundancy (handled by AdultPreprocessing class).\n",
    "\n",
    "Create a deep copy of this DataFrame “df_copy” for use in Experiment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 98 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   age                                        32561 non-null  float64\n",
      " 1   fnlwgt                                     32561 non-null  int64  \n",
      " 2   education-num                              32561 non-null  int64  \n",
      " 3   capital-gain                               32561 non-null  int64  \n",
      " 4   capital-loss                               32561 non-null  int64  \n",
      " 5   hours-per-week                             32561 non-null  int64  \n",
      " 6   workclass_Local-gov                        32561 non-null  int32  \n",
      " 7   workclass_Never-worked                     32561 non-null  int32  \n",
      " 8   workclass_Private                          32561 non-null  int32  \n",
      " 9   workclass_Self-emp-inc                     32561 non-null  int32  \n",
      " 10  workclass_Self-emp-not-inc                 32561 non-null  int32  \n",
      " 11  workclass_State-gov                        32561 non-null  int32  \n",
      " 12  workclass_Without-pay                      32561 non-null  int32  \n",
      " 13  education_11th                             32561 non-null  int32  \n",
      " 14  education_12th                             32561 non-null  int32  \n",
      " 15  education_1st-4th                          32561 non-null  int32  \n",
      " 16  education_5th-6th                          32561 non-null  int32  \n",
      " 17  education_7th-8th                          32561 non-null  int32  \n",
      " 18  education_9th                              32561 non-null  int32  \n",
      " 19  education_Assoc-acdm                       32561 non-null  int32  \n",
      " 20  education_Assoc-voc                        32561 non-null  int32  \n",
      " 21  education_Bachelors                        32561 non-null  int32  \n",
      " 22  education_Doctorate                        32561 non-null  int32  \n",
      " 23  education_HS-grad                          32561 non-null  int32  \n",
      " 24  education_Masters                          32561 non-null  int32  \n",
      " 25  education_Preschool                        32561 non-null  int32  \n",
      " 26  education_Prof-school                      32561 non-null  int32  \n",
      " 27  education_Some-college                     32561 non-null  int32  \n",
      " 28  marital-status_Married-AF-spouse           32561 non-null  int32  \n",
      " 29  marital-status_Married-civ-spouse          32561 non-null  int32  \n",
      " 30  marital-status_Married-spouse-absent       32561 non-null  int32  \n",
      " 31  marital-status_Never-married               32561 non-null  int32  \n",
      " 32  marital-status_Separated                   32561 non-null  int32  \n",
      " 33  marital-status_Widowed                     32561 non-null  int32  \n",
      " 34  occupation_Armed-Forces                    32561 non-null  int32  \n",
      " 35  occupation_Craft-repair                    32561 non-null  int32  \n",
      " 36  occupation_Exec-managerial                 32561 non-null  int32  \n",
      " 37  occupation_Farming-fishing                 32561 non-null  int32  \n",
      " 38  occupation_Handlers-cleaners               32561 non-null  int32  \n",
      " 39  occupation_Machine-op-inspct               32561 non-null  int32  \n",
      " 40  occupation_Other-service                   32561 non-null  int32  \n",
      " 41  occupation_Priv-house-serv                 32561 non-null  int32  \n",
      " 42  occupation_Prof-specialty                  32561 non-null  int32  \n",
      " 43  occupation_Protective-serv                 32561 non-null  int32  \n",
      " 44  occupation_Sales                           32561 non-null  int32  \n",
      " 45  occupation_Tech-support                    32561 non-null  int32  \n",
      " 46  occupation_Transport-moving                32561 non-null  int32  \n",
      " 47  relatioship_Not-in-family                  32561 non-null  int32  \n",
      " 48  relatioship_Other-relative                 32561 non-null  int32  \n",
      " 49  relatioship_Own-child                      32561 non-null  int32  \n",
      " 50  relatioship_Unmarried                      32561 non-null  int32  \n",
      " 51  relatioship_Wife                           32561 non-null  int32  \n",
      " 52  race_Asian-Pac-Islander                    32561 non-null  int32  \n",
      " 53  race_Black                                 32561 non-null  int32  \n",
      " 54  race_Other                                 32561 non-null  int32  \n",
      " 55  race_White                                 32561 non-null  int32  \n",
      " 56  sex_Male                                   32561 non-null  int32  \n",
      " 57  native-country_Canada                      32561 non-null  int32  \n",
      " 58  native-country_China                       32561 non-null  int32  \n",
      " 59  native-country_Columbia                    32561 non-null  int32  \n",
      " 60  native-country_Cuba                        32561 non-null  int32  \n",
      " 61  native-country_Dominican-Republic          32561 non-null  int32  \n",
      " 62  native-country_Ecuador                     32561 non-null  int32  \n",
      " 63  native-country_El-Salvador                 32561 non-null  int32  \n",
      " 64  native-country_England                     32561 non-null  int32  \n",
      " 65  native-country_France                      32561 non-null  int32  \n",
      " 66  native-country_Germany                     32561 non-null  int32  \n",
      " 67  native-country_Greece                      32561 non-null  int32  \n",
      " 68  native-country_Guatemala                   32561 non-null  int32  \n",
      " 69  native-country_Haiti                       32561 non-null  int32  \n",
      " 70  native-country_Holand-Netherlands          32561 non-null  int32  \n",
      " 71  native-country_Honduras                    32561 non-null  int32  \n",
      " 72  native-country_Hong                        32561 non-null  int32  \n",
      " 73  native-country_Hungary                     32561 non-null  int32  \n",
      " 74  native-country_India                       32561 non-null  int32  \n",
      " 75  native-country_Iran                        32561 non-null  int32  \n",
      " 76  native-country_Ireland                     32561 non-null  int32  \n",
      " 77  native-country_Italy                       32561 non-null  int32  \n",
      " 78  native-country_Jamaica                     32561 non-null  int32  \n",
      " 79  native-country_Japan                       32561 non-null  int32  \n",
      " 80  native-country_Laos                        32561 non-null  int32  \n",
      " 81  native-country_Mexico                      32561 non-null  int32  \n",
      " 82  native-country_Nicaragua                   32561 non-null  int32  \n",
      " 83  native-country_Outlying-US(Guam-USVI-etc)  32561 non-null  int32  \n",
      " 84  native-country_Peru                        32561 non-null  int32  \n",
      " 85  native-country_Philippines                 32561 non-null  int32  \n",
      " 86  native-country_Poland                      32561 non-null  int32  \n",
      " 87  native-country_Portugal                    32561 non-null  int32  \n",
      " 88  native-country_Puerto-Rico                 32561 non-null  int32  \n",
      " 89  native-country_Scotland                    32561 non-null  int32  \n",
      " 90  native-country_South                       32561 non-null  int32  \n",
      " 91  native-country_Taiwan                      32561 non-null  int32  \n",
      " 92  native-country_Thailand                    32561 non-null  int32  \n",
      " 93  native-country_Trinadad&Tobago             32561 non-null  int32  \n",
      " 94  native-country_United-States               32561 non-null  int32  \n",
      " 95  native-country_Vietnam                     32561 non-null  int32  \n",
      " 96  native-country_Yugoslavia                  32561 non-null  int32  \n",
      " 97  income_>50K                                32561 non-null  int32  \n",
      "dtypes: float64(1), int32(92), int64(5)\n",
      "memory usage: 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "df = ap.get_df()\n",
    "df_copy = df.copy()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive data analysis is skipped because the same data was already explored in assignment 1.\n",
    "Please see https://github.com/zmswanson/ecen878_knn_classifier for details and data analysis from\n",
    "assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Matrix X and Target y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a “target” DataFrame containing the target variable and a “features” DataFrame containing all\n",
    "feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape: (32561,) and features shape: (32561, 97)\n"
     ]
    }
   ],
   "source": [
    "target = df.pop('income_>50K')\n",
    "features = df\n",
    "\n",
    "print(f\"target shape: {target.shape} and features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the “features” and “target” DataFrame objects, create a NumPy ndarray for the feature matrix X\n",
    "and a 1D array for the target y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32561, 97) and y shape: (32561,)\n"
     ]
    }
   ],
   "source": [
    "X = features.to_numpy()\n",
    "y = target.to_numpy()\n",
    "\n",
    "print(f\"X shape: {X.shape} and y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the Dataset into Train & Test Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and test subsets (20% for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, further split the training set into training and validation subsets (20% for validation).\n",
    "\n",
    "Display the shape of each subset for both the feature matrix and target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20838, 97) and y_train shape: (20838,)\n",
      "X_val shape: (5210, 97) and y_val shape: (5210,)\n",
      "X_test shape: (6513, 97) and y_test shape: (6513,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} and y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape} and y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape} and y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the three data subsets. Ensure that there is no data leakage. This is achieved by\n",
    "fitting the standardizing model on the training set and then applying the same model to transform\n",
    "the validation and test sets. This ensures that we aren't inadvertently \"peaking\" at the validation\n",
    "or test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an LNN model for binary classification. Initially, the Dense layer should have the \n",
    "“kernel_regularizer” set to None. Later you will change this value as instructed below.\n",
    "\n",
    "Display the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ZMS_LNN_Binary_Classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Output_Layer (Dense)        (None, 1)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The following model creation is borrowed and modified from \n",
    "# https://github.com/rhasanbd/Linear-Neural-Networks/blob/main/Linear%20Neural%20Network-1-Binary%20Classification-Linearly%20Separable.ipynb\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reseed the random number generator to get consistent results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.models.Sequential(name=\"ZMS_LNN_Binary_Classifier\")\n",
    "model.add(tf.keras.layers.Input(shape=X_train.shape[1], name=\"Input_Layer\"))\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(units=1, kernel_initializer=\"zeros\", activation=\"sigmoid\",\n",
    "        kernel_regularizer=None, name=\"Output_Layer\", use_bias=True)\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Conduct the following experiments. For each experiment:\n",
    "- Display learning curves (accuracy vs. epochs, and loss vs. epochs). \n",
    "- Clearly annotate your code.\n",
    "- Report performance: Train and test accuracy, test confusion matrix, and test classification report\n",
    "\n",
    "For the following two experiments, you will perform hyperparameter tuning to enhance the performance\n",
    "of your LNN models. This tuning should be conducted using the Keras Tuner library, where you can\n",
    "choose either the RandomSearch or Hyperband algorithms to efficiently explore the hyperparameter \n",
    "space.\n",
    "\n",
    "Specifically, you will tune the learning rate, number of epochs, and mini-batch size. Additionally,\n",
    "you must develop your own heuristic to define the lower and upper ranges for these hyperparameters\n",
    "and briefly state your heuristic in no more than a few lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Tune hyperparameters, including learning rate, number of epochs, and mini-batch size. You may also\n",
    "apply regularization (both weight-based and early stopping) as needed to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "Using the deep copy DataFrame “df_copy”, repeat the steps to create target and feature DataFrames.\n",
    "\n",
    "Split the dataset into training and test subsets (20% for testing) and then into training and\n",
    "validation subsets (20% for validation) without standardizing the dataset.\n",
    "\n",
    "Create an optimal logistic regression LNN model. Select optimal hyperparameters and regularizers to\n",
    "ensure that the test performance of this experiment is comparable to that of Experiment 1. You must\n",
    "optimize the model’s performance to align it closely with Experiment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecen878-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
